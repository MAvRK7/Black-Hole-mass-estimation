{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3XFV3KYYNVq_",
        "outputId": "d339d9a7-8b83-45bf-d8ef-c25d9197ba72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qiskit\n",
            "  Downloading qiskit-1.2.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting rustworkx>=0.15.0 (from qiskit)\n",
            "  Downloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.13.1)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.13.2)\n",
            "Collecting dill>=0.3 (from qiskit)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (2.8.2)\n",
            "Collecting stevedore>=3.0.0 (from qiskit)\n",
            "  Downloading stevedore-5.2.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qiskit) (4.12.2)\n",
            "Collecting symengine>=0.11 (from qiskit)\n",
            "  Downloading symengine-0.11.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.16.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0 (from stevedore>=3.0.0->qiskit)\n",
            "  Downloading pbr-6.0.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n",
            "Downloading qiskit-1.2.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.2.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading symengine-0.11.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (39.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.4/39.4 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pbr-6.0.0-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.5/107.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: symengine, rustworkx, pbr, dill, stevedore, qiskit\n",
            "Successfully installed dill-0.3.8 pbr-6.0.0 qiskit-1.2.0 rustworkx-0.15.1 stevedore-5.2.0 symengine-0.11.0\n",
            "Collecting qiskit_machine_learning\n",
            "  Downloading qiskit_machine_learning-0.7.2-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: qiskit>=0.44 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (1.2.0)\n",
            "Collecting qiskit-algorithms>=0.2.0 (from qiskit_machine_learning)\n",
            "  Downloading qiskit_algorithms-0.3.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (5.9.5)\n",
            "Requirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (1.3.2)\n",
            "Collecting fastdtw (from qiskit_machine_learning)\n",
            "  Downloading fastdtw-0.3.4.tar.gz (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=40.1.0 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (71.0.4)\n",
            "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (0.3.8)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit_machine_learning) (0.15.1)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit_machine_learning) (1.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit_machine_learning) (2.8.2)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit_machine_learning) (5.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit_machine_learning) (4.12.2)\n",
            "Requirement already satisfied: symengine>=0.11 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit_machine_learning) (0.11.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->qiskit_machine_learning) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->qiskit_machine_learning) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit>=0.44->qiskit_machine_learning) (1.16.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from stevedore>=3.0.0->qiskit>=0.44->qiskit_machine_learning) (6.0.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit>=0.44->qiskit_machine_learning) (1.3.0)\n",
            "Downloading qiskit_machine_learning-0.7.2-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.8/97.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qiskit_algorithms-0.3.0-py3-none-any.whl (308 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.6/308.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fastdtw\n",
            "  Building wheel for fastdtw (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastdtw: filename=fastdtw-0.3.4-cp310-cp310-linux_x86_64.whl size=512549 sha256=40554898896a88f3752d64ff8c0c868a339572103604372f9f97d66079a382e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/c8/f7/c25448dab74c3acf4848bc25d513c736bb93910277e1528ef4\n",
            "Successfully built fastdtw\n",
            "Installing collected packages: fastdtw, qiskit-algorithms, qiskit_machine_learning\n",
            "Successfully installed fastdtw-0.3.4 qiskit-algorithms-0.3.0 qiskit_machine_learning-0.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install qiskit\n",
        "!pip install qiskit_machine_learning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit.circuit import Parameter\n",
        "from qiskit.quantum_info import SparsePauliOp\n",
        "from qiskit_machine_learning.connectors import TorchConnector\n",
        "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
        "from qiskit.primitives import Estimator\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "B8fi7drF0jNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "def load_data(path):\n",
        "    data = pd.read_csv(path)\n",
        "    return data\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/Classroom/MiniProject_BlackHoleMassEstimation/typeII_AGN_metadata.csv'\n",
        "df = load_data(dataset_path)"
      ],
      "metadata": {
        "id": "8c4-qpks90xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling missing values by replacing with column mean\n",
        "df.fillna(df.mean(), inplace=True)\n",
        "\n",
        "# Target and Features\n",
        "target_column = 'log_bh_mass'\n",
        "feature_columns = [\n",
        "    'h_beta_flux', 'h_beta_flux_err', 'oiii_5007_flux', 'oiii_5007_flux_err',\n",
        "    'h_alpha_flux', 'h_alpha_flux_err', 'nii_6584_flux', 'nii_6584_flux_err',\n",
        "    'log_stellar_sigma', 'psfMag_u', 'psfMag_g', 'psfMag_r', 'psfMag_i',\n",
        "    'psfMag_z', 'psfMagErr_u', 'psfMagErr_g', 'psfMagErr_r', 'psfMagErr_i',\n",
        "    'psfMagErr_z', 'mendel_logM_p50', 'mendel_logM_p16', 'mendel_logM_p84',\n",
        "    'mendel_logMt_p50', 'mendel_logMt_p16', 'mendel_logMt_p84',\n",
        "    'mendel_logMb_p50', 'mendel_logMb_p16', 'mendel_logMb_p84',\n",
        "    'mendel_logMd_p50', 'mendel_logMd_p16', 'mendel_logMd_p84',\n",
        "    'simard_b_t_g', 'simard_e_b_t_g', 'simard_b_t_r', 'simard_e_b_t_r',\n",
        "    'simard_Rhlg', 'simard_Rhlr', 'simard_Rchl_g', 'simard_Rchl_r',\n",
        "    'simard_Re', 'simard_e_Re', 'simard_e', 'simard_e_e', 'simard_nb',\n",
        "    'simard_e_nb', 'simard_PpS', 'simard_Pn4'\n",
        "]\n",
        "\n",
        "X = df[feature_columns]\n",
        "y = df[target_column]"
      ],
      "metadata": {
        "id": "E4t_0FHR9-tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the features using Min-Max Scaler\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Apply PCA to reduce the dimensionality to 4 components\n",
        "pca = PCA(n_components=4)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Convert the reduced dataset to torch tensors\n",
        "X_pca_tensor = torch.tensor(X_pca, dtype=torch.float32)\n",
        "\n",
        "# Normalize the target variable using Min-Max Scaler\n",
        "y_scaler = MinMaxScaler()\n",
        "y_scaled = y.values.reshape(-1, 1)  # Reshape for scaler\n",
        "y_scaled = y_scaler.fit_transform(y_scaled)\n",
        "y_tensor = torch.tensor(y_scaled, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "9txXNUuw9_g_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the quantum circuit to work with 4 qubits\n",
        "num_qubits = X_pca.shape[1]  # This should be 4 now\n",
        "qc = QuantumCircuit(num_qubits)\n",
        "params = [Parameter(f'theta_{i}') for i in range(num_qubits)]\n",
        "\n",
        "# Simple parametric circuit with the reduced number of qubits\n",
        "for i in range(num_qubits):\n",
        "    qc.rx(params[i], i)\n",
        "\n",
        "# Define the observable for measurement with the new number of qubits\n",
        "observable = SparsePauliOp(\"Z\" * num_qubits, 1)"
      ],
      "metadata": {
        "id": "WrneqtuT-EE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(observable)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nxzasW9Ki-l",
        "outputId": "b63186d3-fc88-4f80-ca02-1189331f9d05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SparsePauliOp(['ZZZZ'],\n",
            "              coeffs=[1.+0.j])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qnn = EstimatorQNN(circuit=qc, observables=observable, input_params=params, estimator=None, input_gradients=True)\n",
        "\n",
        "qnn_torch = TorchConnector(qnn)\n",
        "\n",
        "class QNNRegressor(nn.Module):\n",
        "    def __init__(self, qnn):\n",
        "        super(QNNRegressor, self).__init__()\n",
        "\n",
        "        # Classical layers\n",
        "        self.fc1 = nn.Linear(4, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 16)\n",
        "\n",
        "        # Quantum Neural Network\n",
        "        self.qnn = qnn\n",
        "\n",
        "        # Output layer for combining the classical and quantum outputs\n",
        "        self.fc4 = nn.Linear(16 + 1, 1)  # Concatenate classical and QNN outputs\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply classical layers\n",
        "        x_classical = torch.relu(self.fc1(x))\n",
        "        x_classical = torch.relu(self.fc2(x_classical))\n",
        "        x_classical = torch.relu(self.fc3(x_classical))\n",
        "\n",
        "        # Apply QNN\n",
        "        x_qnn = self.qnn(x)\n",
        "\n",
        "        # Concatenate classical and QNN outputs\n",
        "        x_combined = torch.cat((x_classical, x_qnn), dim=1)\n",
        "\n",
        "        # Apply final output layer\n",
        "        return self.fc4(x_combined)\n",
        "\n",
        "model = QNNRegressor(qnn_torch)"
      ],
      "metadata": {
        "id": "PpZ_kCfd_CTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Loss and Optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Lower learning rate\\\n",
        "\n",
        "last_loss = 0\n",
        "\n",
        "# Train the Model\n",
        "epochs = 100  # Increase number of epochs\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass with the reduced feature tensor\n",
        "    outputs = model(X_pca_tensor)\n",
        "\n",
        "    # Compute the loss\n",
        "    loss = criterion(outputs, y_tensor)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Store the last loss\n",
        "    last_loss = loss.item()\n",
        "\n",
        "    # Print loss for monitoring\n",
        "    print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6haAGdX6_DRC",
        "outputId": "5d2e0d08-dbc3-4944-8fb9-e02db016f8a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Loss: 0.0710\n",
            "Epoch 2/100, Loss: 0.0671\n",
            "Epoch 3/100, Loss: 0.0635\n",
            "Epoch 4/100, Loss: 0.0600\n",
            "Epoch 5/100, Loss: 0.0565\n",
            "Epoch 6/100, Loss: 0.0532\n",
            "Epoch 7/100, Loss: 0.0500\n",
            "Epoch 8/100, Loss: 0.0468\n",
            "Epoch 9/100, Loss: 0.0437\n",
            "Epoch 10/100, Loss: 0.0406\n",
            "Epoch 11/100, Loss: 0.0377\n",
            "Epoch 12/100, Loss: 0.0349\n",
            "Epoch 13/100, Loss: 0.0322\n",
            "Epoch 14/100, Loss: 0.0296\n",
            "Epoch 15/100, Loss: 0.0272\n",
            "Epoch 16/100, Loss: 0.0250\n",
            "Epoch 17/100, Loss: 0.0230\n",
            "Epoch 18/100, Loss: 0.0213\n",
            "Epoch 19/100, Loss: 0.0198\n",
            "Epoch 20/100, Loss: 0.0186\n",
            "Epoch 21/100, Loss: 0.0177\n",
            "Epoch 22/100, Loss: 0.0171\n",
            "Epoch 23/100, Loss: 0.0167\n",
            "Epoch 24/100, Loss: 0.0165\n",
            "Epoch 25/100, Loss: 0.0165\n",
            "Epoch 26/100, Loss: 0.0166\n",
            "Epoch 27/100, Loss: 0.0168\n",
            "Epoch 28/100, Loss: 0.0169\n",
            "Epoch 29/100, Loss: 0.0170\n",
            "Epoch 30/100, Loss: 0.0170\n",
            "Epoch 31/100, Loss: 0.0169\n",
            "Epoch 32/100, Loss: 0.0167\n",
            "Epoch 33/100, Loss: 0.0165\n",
            "Epoch 34/100, Loss: 0.0162\n",
            "Epoch 35/100, Loss: 0.0158\n",
            "Epoch 36/100, Loss: 0.0154\n",
            "Epoch 37/100, Loss: 0.0151\n",
            "Epoch 38/100, Loss: 0.0148\n",
            "Epoch 39/100, Loss: 0.0146\n",
            "Epoch 40/100, Loss: 0.0144\n",
            "Epoch 41/100, Loss: 0.0142\n",
            "Epoch 42/100, Loss: 0.0141\n",
            "Epoch 43/100, Loss: 0.0141\n",
            "Epoch 44/100, Loss: 0.0140\n",
            "Epoch 45/100, Loss: 0.0140\n",
            "Epoch 46/100, Loss: 0.0140\n",
            "Epoch 47/100, Loss: 0.0139\n",
            "Epoch 48/100, Loss: 0.0139\n",
            "Epoch 49/100, Loss: 0.0138\n",
            "Epoch 50/100, Loss: 0.0137\n",
            "Epoch 51/100, Loss: 0.0136\n",
            "Epoch 52/100, Loss: 0.0135\n",
            "Epoch 53/100, Loss: 0.0134\n",
            "Epoch 54/100, Loss: 0.0133\n",
            "Epoch 55/100, Loss: 0.0132\n",
            "Epoch 56/100, Loss: 0.0132\n",
            "Epoch 57/100, Loss: 0.0131\n",
            "Epoch 58/100, Loss: 0.0131\n",
            "Epoch 59/100, Loss: 0.0131\n",
            "Epoch 60/100, Loss: 0.0130\n",
            "Epoch 61/100, Loss: 0.0130\n",
            "Epoch 62/100, Loss: 0.0130\n",
            "Epoch 63/100, Loss: 0.0130\n",
            "Epoch 64/100, Loss: 0.0129\n",
            "Epoch 65/100, Loss: 0.0129\n",
            "Epoch 66/100, Loss: 0.0129\n",
            "Epoch 67/100, Loss: 0.0128\n",
            "Epoch 68/100, Loss: 0.0128\n",
            "Epoch 69/100, Loss: 0.0128\n",
            "Epoch 70/100, Loss: 0.0127\n",
            "Epoch 71/100, Loss: 0.0127\n",
            "Epoch 72/100, Loss: 0.0127\n",
            "Epoch 73/100, Loss: 0.0127\n",
            "Epoch 74/100, Loss: 0.0127\n",
            "Epoch 75/100, Loss: 0.0127\n",
            "Epoch 76/100, Loss: 0.0127\n",
            "Epoch 77/100, Loss: 0.0127\n",
            "Epoch 78/100, Loss: 0.0126\n",
            "Epoch 79/100, Loss: 0.0126\n",
            "Epoch 80/100, Loss: 0.0126\n",
            "Epoch 81/100, Loss: 0.0126\n",
            "Epoch 82/100, Loss: 0.0126\n",
            "Epoch 83/100, Loss: 0.0126\n",
            "Epoch 84/100, Loss: 0.0126\n",
            "Epoch 85/100, Loss: 0.0126\n",
            "Epoch 86/100, Loss: 0.0125\n",
            "Epoch 87/100, Loss: 0.0125\n",
            "Epoch 88/100, Loss: 0.0125\n",
            "Epoch 89/100, Loss: 0.0125\n",
            "Epoch 90/100, Loss: 0.0125\n",
            "Epoch 91/100, Loss: 0.0125\n",
            "Epoch 92/100, Loss: 0.0125\n",
            "Epoch 93/100, Loss: 0.0125\n",
            "Epoch 94/100, Loss: 0.0125\n",
            "Epoch 95/100, Loss: 0.0125\n",
            "Epoch 96/100, Loss: 0.0125\n",
            "Epoch 97/100, Loss: 0.0124\n",
            "Epoch 98/100, Loss: 0.0124\n",
            "Epoch 99/100, Loss: 0.0124\n",
            "Epoch 100/100, Loss: 0.0124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the Model and Compute Metrics\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # Use the PCA-reduced tensor for predictions\n",
        "    predictions = model(X_pca_tensor).numpy().flatten()\n",
        "\n",
        "# Metrics: MSE\n",
        "y_range = y.max() - y.min()\n",
        "\n",
        "mse = last_loss\n",
        "accuracy = (1-last_loss/y_range)*100\n",
        "\n",
        "print (\"MSE is \", mse)\n",
        "print (\"Accuracy by MSE is \", accuracy),"
      ],
      "metadata": {
        "id": "c8h3kzW1_F9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b7ca0a2-df6b-47ab-f755-a1292d37464a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE is  0.012427426874637604\n",
            "Accuracy by MSE is  99.75353307288032\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None,)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}