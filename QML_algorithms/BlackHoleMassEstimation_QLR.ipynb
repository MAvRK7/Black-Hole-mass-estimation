{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2N23mpsD0ijm",
        "outputId": "670570e1-72b5-4bcc-d367-10fe137dd0fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\sathw\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.5.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\sathw\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\sathw\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.5.1)\n",
            "Requirement already satisfied: pennylane in c:\\users\\sathw\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.37.0)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\sathw\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.6.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement pennylane-sklearn (from versions: none)\n",
            "ERROR: No matching distribution found for pennylane-sklearn\n"
          ]
        }
      ],
      "source": [
        "pip install pandas numpy scikit-learn pennylane matplotlib pennylane-sklearn pennylane-lightning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wurgHiY0ijn",
        "outputId": "49ccc51a-41e2-4fae-b701-2cbb545c8fbd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\sathw\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\autograd\\tracer.py:14: UserWarning: Output seems independent of input.\n",
            "  warnings.warn(\"Output seems independent of input.\")\n",
            "c:\\Users\\sathw\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\autograd\\tracer.py:14: UserWarning: Output seems independent of input.\n",
            "  warnings.warn(\"Output seems independent of input.\")\n",
            "c:\\Users\\sathw\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\autograd\\tracer.py:14: UserWarning: Output seems independent of input.\n",
            "  warnings.warn(\"Output seems independent of input.\")\n",
            "c:\\Users\\sathw\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\autograd\\tracer.py:14: UserWarning: Output seems independent of input.\n",
            "  warnings.warn(\"Output seems independent of input.\")\n",
            "c:\\Users\\sathw\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\autograd\\tracer.py:14: UserWarning: Output seems independent of input.\n",
            "  warnings.warn(\"Output seems independent of input.\")\n"
          ]
        }
      ],
      "source": [
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 3: Load and Mount Dataset\n",
        "# Replace 'path_to_dataset.csv' with the actual path to your dataset\n",
        "dataset_path = r'C:\\Users\\sathw\\OneDrive\\Desktop\\typeII_AGN_metadata.csv'\n",
        "data = pd.read_csv(dataset_path)\n",
        "\n",
        "# Step 4: Define Target and Features\n",
        "target_column = 'log_bh_mass'\n",
        "feature_columns = [\n",
        "    'h_beta_flux', 'h_beta_flux_err', 'oiii_5007_flux', 'oiii_5007_flux_err',\n",
        "    'h_alpha_flux', 'h_alpha_flux_err', 'nii_6584_flux', 'nii_6584_flux_err',\n",
        "    'log_stellar_sigma', 'psfMag_u', 'psfMag_g', 'psfMag_r', 'psfMag_i', 'psfMag_z',\n",
        "    'psfMagErr_u', 'psfMagErr_g', 'psfMagErr_r', 'psfMagErr_i', 'psfMagErr_z',\n",
        "    'mendel_logM_p50', 'mendel_logM_p16', 'mendel_logM_p84', 'mendel_logMt_p50',\n",
        "    'mendel_logMt_p16', 'mendel_logMt_p84', 'mendel_logMb_p50', 'mendel_logMb_p16',\n",
        "    'mendel_logMb_p84', 'mendel_logMd_p50', 'mendel_logMd_p16', 'mendel_logMd_p84',\n",
        "    'simard_b_t_g', 'simard_e_b_t_g', 'simard_b_t_r', 'simard_e_b_t_r', 'simard_Rhlg',\n",
        "    'simard_Rhlr', 'simard_Rchl_g', 'simard_Rchl_r', 'simard_Re', 'simard_e_Re',\n",
        "    'simard_e', 'simard_e_e', 'simard_nb', 'simard_e_nb', 'simard_PpS', 'simard_Pn4'\n",
        "]\n",
        "\n",
        "# Step 5: Handle Missing Values\n",
        "data.fillna(data.mean(), inplace=True)\n",
        "\n",
        "# Step 6: Normalize Features and Target using Min-Max Normalization\n",
        "scaler_features = MinMaxScaler()\n",
        "features = scaler_features.fit_transform(data[feature_columns])\n",
        "\n",
        "scaler_target = MinMaxScaler()\n",
        "target = scaler_target.fit_transform(data[[target_column]]).flatten()\n",
        "\n",
        "# Step 7: Dimensionality Reduction using PCA\n",
        "pca = PCA(n_components=4)\n",
        "features_reduced = pca.fit_transform(features)\n",
        "\n",
        "# Step 8: Define Quantum Device and Circuit\n",
        "n_qubits = 4\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def quantum_circuit(x):\n",
        "    for i in range(n_qubits):\n",
        "        qml.RX(x[i], wires=i)\n",
        "        qml.RY(x[i], wires=i)\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
        "\n",
        "def quantum_feature_map(x):\n",
        "    return np.array(quantum_circuit(x))\n",
        "\n",
        "# Step 9: Define Quantum Linear Regression Model\n",
        "class QuantumLinearRegression:\n",
        "    def __init__(self, n_features):\n",
        "        self.n_features = n_features\n",
        "        self.weights = np.zeros(n_features, requires_grad=True)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.dot(X, self.weights)\n",
        "\n",
        "    def cost(self, X, y):\n",
        "        predictions = self.predict(X)\n",
        "        return np.mean((predictions - y) ** 2)\n",
        "\n",
        "    def fit(self, X, y, epochs=100, lr=0.01):\n",
        "        opt = qml.GradientDescentOptimizer(stepsize=lr)\n",
        "        for epoch in range(epochs):\n",
        "            self.weights = opt.step(lambda w: self.cost(X, y), self.weights)\n",
        "\n",
        "# Step 10: Run Quantum Linear Regression with 3-Fold Validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "r2_scores, mae_scores, mse_scores, rmse_scores = [], [], [], []\n",
        "\n",
        "for train_index, test_index in kf.split(features_reduced):\n",
        "    X_train, X_test = features_reduced[train_index], features_reduced[test_index]\n",
        "    y_train, y_test = target[train_index], target[test_index]\n",
        "\n",
        "    X_train_quantum = np.array([quantum_feature_map(x) for x in X_train])\n",
        "    X_test_quantum = np.array([quantum_feature_map(x) for x in X_test])\n",
        "\n",
        "    model = QuantumLinearRegression(n_features=n_qubits)\n",
        "    model.fit(X_train_quantum, y_train, epochs=100, lr=0.01)\n",
        "\n",
        "    y_pred = model.predict(X_test_quantum)\n",
        "\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    r2_scores.append(r2)\n",
        "    mae_scores.append(mae)\n",
        "    mse_scores.append(mse)\n",
        "    rmse_scores.append(rmse)\n",
        "\n",
        "# Step 11: Calculate Error Metrics\n",
        "r2_mean = np.mean(r2_scores)\n",
        "mae_mean, mae_std = np.mean(mae_scores), np.std(mae_scores)\n",
        "mse_mean, mse_std = np.mean(mse_scores), np.std(mse_scores)\n",
        "rmse_mean, rmse_std = np.mean(rmse_scores), np.std(rmse_scores)\n",
        "\n",
        "mae_accuracy = (1 - mae_mean / (np.max(target) - np.min(target))) * 100\n",
        "mse_accuracy = (1 - mse_mean / (np.max(target) - np.min(target))) * 100\n",
        "rmse_accuracy = (1 - rmse_mean / (np.max(target) - np.min(target))) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wafLTZdy0ijo",
        "outputId": "6bbceb60-5799-4630-d737-308bf55ba02e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE: 0.4628 ± 0.0016 (53.72%)\n",
            "MSE: 0.2301 ± 0.0014 (76.99%)\n",
            "RMSE: 0.4797 ± 0.0015 (52.03%)\n"
          ]
        }
      ],
      "source": [
        "print(f\"MAE: {mae_mean:.4f} ± {mae_std:.4f} ({mae_accuracy:.2f}%)\")\n",
        "print(f\"MSE: {mse_mean:.4f} ± {mse_std:.4f} ({mse_accuracy:.2f}%)\")\n",
        "print(f\"RMSE: {rmse_mean:.4f} ± {rmse_std:.4f} ({rmse_accuracy:.2f}%)\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}